{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsPb55wLT0ci",
        "outputId": "34305eac-b4a4-4311-81c1-8d065794ceea"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.25.1\n",
        "# !pip install pytorch-lightning==1.6.4\n",
        "# !pip install timm==0.5.4\n",
        "# !pip install gradio\n",
        "# !pip install donut-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g2Mn2wW-UNZV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import gradio as gr\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from donut import DonutModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8_alWsH5UXWi"
      },
      "outputs": [],
      "source": [
        "def demo_process_vqa(input_img, question):\n",
        "    global pretrained_model, task_prompt, task_name\n",
        "    input_img = Image.fromarray(input_img)\n",
        "    user_prompt = task_prompt.replace(\"{user_input}\", question)\n",
        "    output = pretrained_model.inference(input_img, prompt=user_prompt)[\"predictions\"][0]\n",
        "    return output\n",
        "\n",
        "\n",
        "def demo_process(input_img):\n",
        "    global pretrained_model, task_prompt, task_name\n",
        "    input_img = Image.fromarray(input_img)\n",
        "    output = pretrained_model.inference(image=input_img, prompt=task_prompt)[\"predictions\"][0]\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "f7RoSOEXUa6i",
        "outputId": "0dc8f04b-4711-47ad-b3f8-fa462a15ec17"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n",
            "/data/miniconda3/envs/donut/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:453: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--task\", type=str, default=\"cord-v2\")\n",
        "parser.add_argument(\"--pretrained_path\", type=str, default=\"naver-clova-ix/donut-base-finetuned-cord-v2\")\n",
        "args, left_argv = parser.parse_known_args()\n",
        "\n",
        "task_name = args.task\n",
        "if \"docvqa\" == task_name:\n",
        "    task_prompt = \"<s_docvqa><s_question>{user_input}</s_question><s_answer>\"\n",
        "else:  # rvlcdip, cord, ...\n",
        "    task_prompt = f\"<s_{task_name}>\"\n",
        "\n",
        "pretrained_model = DonutModel.from_pretrained(args.pretrained_path)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    pretrained_model.half()\n",
        "    device = torch.device(\"cuda\")\n",
        "    pretrained_model.to(device)\n",
        "else:\n",
        "    pretrained_model.encoder.to(torch.bfloat16)\n",
        "\n",
        "pretrained_model.eval()\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=demo_process_vqa if task_name == \"docvqa\" else demo_process,\n",
        "    inputs=[\"image\", \"text\"] if task_name == \"docvqa\" else \"image\",\n",
        "    outputs=\"json\",\n",
        "    title=f\"Donut üç© demonstration for `{task_name}` task\",\n",
        ")\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuBLQ3Cp3S6D"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
